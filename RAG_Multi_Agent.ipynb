{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790f2770",
   "metadata": {},
   "source": [
    "# üß† Notebook Technique - Impl√©mentation du RAG Agentique\n",
    "\n",
    "Bienvenue dans ce notebook, compagnon technique du m√©moire intitul√© **\"D√©veloppement d‚Äôun Assistant Intelligent interne √† BNP Paribas El Djazair\"**.  \n",
    "Ce document contient l'ensemble du code op√©rationnel li√© √† l‚Äôimpl√©mentation du syst√®me **RAG (Retrieval-Augmented Generation)** avec une **architecture multi-agents** telle que d√©crite dans le m√©moire.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå √Ä propos de ce notebook\n",
    "\n",
    "- Ce notebook sert de **compl√©ment technique** au m√©moire, permettant de **visualiser et tester** les diff√©rentes composantes du syst√®me RAG agentique.\n",
    "- Chaque agent pr√©sent√© dans le m√©moire (ex. : Agent de recherche, Agent de synth√®se, etc.) est impl√©ment√© ici de mani√®re fonctionnelle.\n",
    "- Le pipeline complet du syst√®me RAG y est cod√©, depuis l‚Äôextraction des donn√©es jusqu‚Äô√† la g√©n√©ration augment√©e.\n",
    "\n",
    "## üß± Structure du code\n",
    "\n",
    "Le notebook est structur√© comme suit :\n",
    "1. **Importations & configuration**\n",
    "2. **Chargement et vectorisation des donn√©es**\n",
    "3. **D√©finition des agents**\n",
    "4. **M√©canisme d'orchestration' et ex√©cution**\n",
    "5. **Tests et d√©monstrations**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Remarques\n",
    "\n",
    "- Tous les blocs de code sont **fonctionnels** et peuvent √™tre ex√©cut√©s dans l'ordre.\n",
    "- Certaines cellules peuvent n√©cessiter un acc√®s √† des **fichiers locaux**.\n",
    "- Des **commentaires explicites** sont ajout√©s dans chaque section pour faciliter la navigation dans le code.\n",
    "\n",
    "---\n",
    "\n",
    "> üìö Pour les d√©tails th√©oriques et le choix des architectures, veuillez vous r√©f√©rer au chapitre [5] du m√©moire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671fbd66",
   "metadata": {},
   "source": [
    "### Import des biblioth√®ques utilis√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, fitz\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import T5ForConditionalGeneration\n",
    "import PyPDF2\n",
    "from typing import List, Optional, Tuple\n",
    "import re\n",
    "from typing import ClassVar, Any\n",
    "import string\n",
    "from string import punctuation\n",
    "import spacy\n",
    "from langchain.llms.base import LLM\n",
    "from litellm import completion\n",
    "from crewai import Agent, Task, Crew\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from crewai import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f546a8",
   "metadata": {},
   "source": [
    "## Pr√©paration, pretraitement et stockage des donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_folders(parent_folder: str) -> List[Tuple[str, str, int, str]]:\n",
    "\n",
    "    documents = []\n",
    "    for domaine in os.listdir(parent_folder):\n",
    "        domaine_path = os.path.join(parent_folder, domaine)\n",
    "        if os.path.isdir(domaine_path):\n",
    "            for filename in os.listdir(domaine_path):\n",
    "                if filename.lower().endswith(\".pdf\"):\n",
    "                    pdf_path = os.path.join(domaine_path, filename)\n",
    "                    doc = fitz.open(pdf_path)\n",
    "                    for page_number, page in enumerate(doc, start=1):\n",
    "                        page_text = page.get_text(\"text\")\n",
    "                        if page_text and page_text.strip():\n",
    "                            documents.append((\n",
    "                                domaine,              \n",
    "                                filename,             \n",
    "                                page_number,          \n",
    "                                page_text.strip()    \n",
    "                            ))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea3afe",
   "metadata": {},
   "source": [
    "### Cleaning des textes extraits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ef71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Stopwords sp√©cifiques √† conserver en mode \"lite\"\n",
    "stop_keep = {'mais', 'donc', 'cependant', 'si', 'car'}\n",
    "\n",
    "def clean_text(text, mode=\"lite\"):\n",
    "    # Normalisation de base\n",
    "    text = re.sub(r\"\\s+\", \" \", text.strip())\n",
    "    doc = nlp(text)\n",
    "\n",
    "    if mode == \"hard\":\n",
    "        # Supprimer tous les stopwords et mots courts, conserver uniquement les mots informatifs\n",
    "        tokens = [\n",
    "            token.text.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space and len(token.text) > 2\n",
    "        ]\n",
    "    elif mode == \"lite\":\n",
    "        # Supprimer tous les stopwords sauf les connecteurs utiles\n",
    "        tokens = [\n",
    "            token.text.lower()\n",
    "            for token in doc\n",
    "            if not token.is_punct and not token.is_space and (not token.is_stop or token.text.lower() in stop_keep)\n",
    "        ]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498536b",
   "metadata": {},
   "source": [
    "### Chunking s√©mentique intelligent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_chunking(text, min_chunk_size=500, max_chunk_size=1000):\n",
    "    \"\"\"Segmentation par paragraphes, puis fallback phrase √† phrase.\"\"\"\n",
    "    paragraphs = [p.strip() for p in text.split('\\n') if len(p.strip()) > 0]\n",
    "    chunks, current_chunk = [], \"\"\n",
    "\n",
    "    for para in paragraphs:\n",
    "        if len(para) > max_chunk_size:\n",
    "            # d√©couper en phrases\n",
    "            for sent in nlp(para).sents:\n",
    "                sentence = sent.text.strip()\n",
    "                if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
    "                    current_chunk += \" \" + sentence\n",
    "                else:\n",
    "                    if len(current_chunk.strip()) >= min_chunk_size:\n",
    "                        chunks.append(current_chunk.strip())\n",
    "                        current_chunk = sentence\n",
    "                    else:\n",
    "                        current_chunk += \" \" + sentence\n",
    "            if current_chunk.strip():\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = \"\"\n",
    "        else:\n",
    "            if len(current_chunk) + len(para) <= max_chunk_size:\n",
    "                current_chunk += \" \" + para\n",
    "            else:\n",
    "                if len(current_chunk.strip()) >= min_chunk_size:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                    current_chunk = para\n",
    "                else:\n",
    "                    current_chunk += \" \" + para\n",
    "\n",
    "    if current_chunk.strip():\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfd4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_informative(text, min_keywords=2, min_length=30):\n",
    "    doc = nlp(text)\n",
    "    # Supprime la d√©pendance aux entit√©s\n",
    "    keywords = [token for token in doc if len(token.text) > 4]\n",
    "    # Accepte aussi les chunks longs m√™me sans keywords\n",
    "    return len(keywords) >= min_keywords or len(text.split()) >= min_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fe1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_chunks(chunks, max_len=900):\n",
    "    fused = []\n",
    "    temp_text = \"\"\n",
    "    current_file = None\n",
    "    pages = set()\n",
    "\n",
    "    for chunk in chunks:\n",
    "        file = chunk[\"file\"]\n",
    "        page = chunk[\"page\"]\n",
    "        content = chunk[\"content_raw\"]\n",
    "\n",
    "        # V√©rifie si on peut fusionner\n",
    "        same_file = (file == current_file or current_file is None)\n",
    "        temp_len = len(temp_text.split()) + len(content.split())\n",
    "        can_fuse = (temp_len < max_len) and same_file\n",
    "\n",
    "        if can_fuse:\n",
    "            temp_text += \" \" + content\n",
    "            pages.add(page)\n",
    "        else:\n",
    "            if temp_text:\n",
    "                page_range = f\"{min(pages)}\" if len(pages) == 1 else f\"{min(pages)}-{max(pages)}\"\n",
    "                fused.append({\n",
    "                    \"file\": current_file,\n",
    "                    \"page\": page_range,\n",
    "                    \"content\": temp_text.strip()\n",
    "                })\n",
    "        # R√©initialisation\n",
    "        temp_text = content\n",
    "        current_file = file\n",
    "        pages = {page}\n",
    "\n",
    "    # Ajouter le dernier\n",
    "    if temp_text:\n",
    "        page_range = f\"{min(pages)}\" if len(pages) == 1 else f\"{min(pages)}-{max(pages)}\"\n",
    "        fused.append({\n",
    "            \"file\": current_file,\n",
    "            \"page\": page_range,\n",
    "            \"content\": temp_text.strip()\n",
    "        })\n",
    "\n",
    "    return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = r'lien vers le fichier qui contient vos documents'\n",
    "embedding_dim = 1024\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_domains(base_folder):\n",
    "    return [\n",
    "        name for name in os.listdir(base_folder)\n",
    "        if os.path.isdir(os.path.join(base_folder, name))\n",
    "    ]\n",
    "\n",
    "domains = detect_domains(parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59497f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {}\n",
    "embeddings = {}\n",
    "chunks = {}\n",
    "\n",
    "for domain in domains:\n",
    "    prefix = f\"{domain}_\"\n",
    "    idx_file = prefix + \"faiss_index.index\"\n",
    "    emb_file = prefix + \"embeddings.npy\"\n",
    "    meta_file = prefix + \"metadata.pkl\"\n",
    "\n",
    "    print(f\"Cr√©ation d'un nouveau index pour {domain}.\")\n",
    "    indices[domain] = faiss.IndexFlatIP(embedding_dim)\n",
    "    embeddings[domain] = np.array([]).reshape(0, embedding_dim)\n",
    "    chunks[domain] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = extract_text_from_pdf_folders(parent_folder)\n",
    "\n",
    "# Trie par domaine\n",
    "from collections import defaultdict\n",
    "chunks_by_domain = defaultdict(list)\n",
    "for domain, filename, page, raw_text in docs:\n",
    "    raw_chunks = hybrid_chunking(raw_text)\n",
    "    fused_chunks = fuse_chunks([{'file': filename, 'page': page, 'content_raw': c} for c in raw_chunks])\n",
    "    for i, chunk in enumerate(fused_chunks):\n",
    "        cleaned_hard = clean_text(chunk['content'], mode=\"hard\")\n",
    "        cleaned_lite = clean_text(chunk['content'], mode=\"lite\")\n",
    "        if len(cleaned_hard) < 10:\n",
    "            continue  # √©vite les chunks inutiles\n",
    "        chunks_by_domain[domain].append({\n",
    "            \"domaine\": domain,\n",
    "            \"file\": chunk['file'],\n",
    "            \"page\": chunk['page'],\n",
    "            \"chunk_id\": i,\n",
    "            \"content_raw\": chunk['content'].strip(),\n",
    "            \"content_lite\": cleaned_lite,\n",
    "            \"content_clean\": cleaned_hard,\n",
    "            \"length\": len(cleaned_hard),\n",
    "            \"nb_words\": len(cleaned_hard.split()),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e2ae6",
   "metadata": {},
   "source": [
    "#### Bloc de Stockage des Donn√©es Vectoris√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca947ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === G√©n√©ration des embeddings normalis√©s ===\n",
    "for domain, domain_chunks in chunks_by_domain.items():\n",
    "    if not domain_chunks:\n",
    "        print(f\"‚ùå Aucun chunk pour {domain}\")\n",
    "        continue\n",
    "\n",
    "    texts = [chunk['content_clean'] for chunk in domain_chunks]\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "    # Cr√©ation FAISS index\n",
    "    index = faiss.IndexFlatIP(embedding_dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Sauvegarde\n",
    "    prefix = f\"{domain}_\"\n",
    "    faiss.write_index(index, prefix + \"faiss_index.index\")\n",
    "    np.save(prefix + \"embeddings.npy\", embeddings)\n",
    "    with open(prefix + \"metadata.pkl\", \"wb\") as f:\n",
    "        pickle.dump(domain_chunks, f)\n",
    "\n",
    "    print(f\"‚úÖ {len(domain_chunks)} chunks index√©s pour le domaine {domain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a4945",
   "metadata": {},
   "source": [
    "### chargement des donn√©es direct si les les vecteurs existent deja "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ad90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {}\n",
    "embeddings = {}\n",
    "chunks = {}\n",
    "\n",
    "for domain in domains:\n",
    "    prefix = f\"{domain}_\"\n",
    "    idx_file = prefix + \"faiss_index.index\"\n",
    "    emb_file = prefix + \"embeddings.npy\"\n",
    "    meta_file = prefix + \"metadata.pkl\"\n",
    "\n",
    "    print(f\"‚úÖ Index FAISS existant charg√© pour {domain}.\")\n",
    "    indices[domain] = faiss.read_index(idx_file)\n",
    "    embeddings[domain] = np.load(emb_file)\n",
    "    with open(meta_file, \"rb\") as f:\n",
    "        chunks[domain] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39366318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BGE reranker model\n",
    "reranker_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-large\")\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(\"BAAI/bge-reranker-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cf151",
   "metadata": {},
   "source": [
    "ici vous trouverez les fonctions retrieve du RAG utilis√© dans l'agent de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5742c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieverAgent:\n",
    "    def __init__(self, model, index, nlp, indexed_chunks, reranker_model, reranker_tokenizer, fallback_k=10):\n",
    "        self.model = model\n",
    "        self.index = index\n",
    "        self.nlp = nlp\n",
    "        self.indexed_chunks = indexed_chunks\n",
    "        self.reranker_model = reranker_model\n",
    "        self.reranker_tokenizer = reranker_tokenizer\n",
    "        self.fallback_k = fallback_k\n",
    "\n",
    "    def retrieve(self, query, k=3, keywords_boost=True, similarity_threshold=0.35):\n",
    "        q_embed = self.model.encode(query, convert_to_numpy=True)\n",
    "        D, I = self.index.search(np.array([q_embed]), k)\n",
    "\n",
    "        results = [\n",
    "            (self.indexed_chunks[i], float(D[0][j]))\n",
    "            for j, i in enumerate(I[0])\n",
    "            if float(D[0][j]) > similarity_threshold\n",
    "        ]\n",
    "\n",
    "        # D√©dupliquer\n",
    "        seen = {}\n",
    "        for chunk, score in results:\n",
    "            key = chunk[\"content_clean\"]\n",
    "            if key not in seen or score > seen[key][1]:\n",
    "                seen[key] = (chunk, score)\n",
    "\n",
    "        retrieved = [v[0] for v in sorted(seen.values(), key=lambda x: -x[1])]\n",
    "\n",
    "        # Boost par mots-cl√©s\n",
    "        if keywords_boost and retrieved:\n",
    "            doc = self.nlp(query)\n",
    "            keywords = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and len(token.text) > 2]\n",
    "\n",
    "            boosted, normal = [], []\n",
    "            for chunk in retrieved:\n",
    "                content_lower = chunk[\"content_clean\"].lower()\n",
    "                if any(keyword in content_lower for keyword in keywords):\n",
    "                    boosted.append(chunk)\n",
    "                else:\n",
    "                    normal.append(chunk)\n",
    "\n",
    "            retrieved = boosted + normal\n",
    "\n",
    "        # Fallback brut si rien trouv√©\n",
    "        if not retrieved:\n",
    "            raw_hits = []\n",
    "            query_lower = query.lower()\n",
    "            for chunk in self.indexed_chunks:\n",
    "                if all(term in chunk[\"content_lite\"].lower() for term in query_lower.split() if len(term) > 2):\n",
    "                    raw_hits.append(chunk)\n",
    "            if raw_hits:\n",
    "                return raw_hits\n",
    "            # Dernier recours\n",
    "            partial_hits = [\n",
    "                chunk for chunk in self.indexed_chunks\n",
    "                if any(term in chunk[\"content_lite\"].lower() for term in query_lower.split() if len(term) > 2)\n",
    "            ]\n",
    "            return partial_hits[:k] if partial_hits else []\n",
    "\n",
    "        return retrieved\n",
    "\n",
    "    def rerank(self, query, passages):\n",
    "        if not passages:\n",
    "            return []\n",
    "\n",
    "        texts = [p[\"content_lite\"] for p in passages]\n",
    "        inputs = self.reranker_tokenizer(\n",
    "            [query] * len(texts), texts,\n",
    "            padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = self.reranker_model(**inputs).logits.squeeze(-1)\n",
    "\n",
    "        reranked = sorted(zip(scores.tolist(), passages), key=lambda x: -x[0])\n",
    "        return [p for _, p in reranked]\n",
    "\n",
    "    def retrieve_combined(self, original_query, reformulated_query, primary_k=5):\n",
    "        enriched_query = f\"Documents internes BNP : {reformulated_query}\"\n",
    "        passages_reformulated = self.retrieve(enriched_query, k=primary_k)\n",
    "        passages_original = self.retrieve(original_query, k=primary_k)\n",
    "\n",
    "        all_passages = passages_reformulated + passages_original\n",
    "        seen = {}\n",
    "        for p in all_passages:\n",
    "            key = p[\"content_clean\"]\n",
    "            if key not in seen:\n",
    "                seen[key] = p\n",
    "\n",
    "        combined_passages = list(seen.values())\n",
    "\n",
    "        if not combined_passages:\n",
    "            print(\"[RetrieverAgent] ‚ö† Aucun passage trouv√©, fallback brut.\")\n",
    "            combined_passages = self.retrieve(original_query, k=self.fallback_k)\n",
    "\n",
    "        reranked_passages = self.rerank(reformulated_query, combined_passages)[:primary_k]\n",
    "        return reranked_passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_extrait(passages: list[dict]) -> str:\n",
    "    result = \"\"\n",
    "    for p in passages:\n",
    "        file = p.get(\"file\", \"Document inconnu\")\n",
    "        page = p.get(\"page\", \"Inconnue\")\n",
    "        contenu = p.get(\"content_lite\", \"\")\n",
    "        result += (\n",
    "            f\"=== DOCUMENT ===\\n\"\n",
    "            f\"Nom : {file}\\n\"\n",
    "            f\"Page : {page}\\n\"\n",
    "            f\"Contenu :\\n{contenu}\\n\\n\"\n",
    "        )\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d80d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_local = 'Ton API'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a77acde",
   "metadata": {},
   "source": [
    "### D√©finition des agents \n",
    "explications necessaire √† partir de la page 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReceptionAgentReformulator(Agent):\n",
    "    def run(self, inputs):\n",
    "        question = inputs.get(\"input\", \"\").strip()\n",
    "        correction_feedback = inputs.get(\"correction_feedback\", \"\").strip()\n",
    "\n",
    "        if not question:\n",
    "            return {\"reformulated_question\": \"‚ö†Ô∏è Aucune question re√ßue pour reformuler.\"}\n",
    "\n",
    "        prompt = f\"Reformule la question de mani√®re claire et pr√©cise uniquement en fran√ßais. Question : {question}\"\n",
    "        if correction_feedback:\n",
    "            prompt += f\"\\n\\nIMPORTANT : Corrige OBLIGATOIREMENT la/les erreur(s) suivante(s) :\\n{correction_feedback}\"\n",
    "\n",
    "        reformulated_question = llm_local(prompt)\n",
    "\n",
    "        return {\n",
    "            \"original_question\": question,\n",
    "            \"reformulated_question\": reformulated_question\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RechercheAgentWithRetriever(Agent):\n",
    "    retriever_agent: Any = None  # D√©clar√© comme attribut normal, pas ClassVar‚ÄØ!\n",
    "\n",
    "    def run(self, inputs):\n",
    "        retriever = self.retriever_agent\n",
    "        original_question = inputs.get(\"original_question\", \"\").strip()\n",
    "        reformulated_question = inputs.get(\"reformulated_question\", \"\").strip()\n",
    "\n",
    "        with open(\"debug_log.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"RECHERCHE_AGENT RUN CALLED with inputs: {inputs}\\n\")\n",
    "\n",
    "        passages = retriever.retrieve_combined(\n",
    "            original_query=original_question,\n",
    "            reformulated_query=reformulated_question,\n",
    "            primary_k=7\n",
    "        )\n",
    "\n",
    "        if not passages:\n",
    "            return {\"context\": \"‚ùå Aucun document trouv√©.\"}\n",
    "\n",
    "        context = format_extrait(passages)\n",
    "        return {\"context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_context(context_str):\n",
    "    \"\"\"\n",
    "    D√©coupe un gros contexte multi-extraits au format [file - page N]\\n<contenu>\n",
    "    Retourne une liste de tuples : (ent√™te, contenu)\n",
    "    \"\"\"\n",
    "    # Pattern : chaque extrait commence par [ ... - page ... ]\n",
    "    pattern = r'(\\[[^\\[\\]]+\\])\\n(.*?)(?=\\n\\n\\[|\\Z)'  # non greedy, jusqu'au prochain [ ...] ou fin\n",
    "    matches = re.findall(pattern, context_str, flags=re.DOTALL)\n",
    "    # Nettoie chaque extrait\n",
    "    cleaned = []\n",
    "    for entete, contenu in matches:\n",
    "        entete = entete.strip()\n",
    "        contenu = contenu.strip().replace('\\n', ' ')\n",
    "        if contenu:  # ignore les vides\n",
    "            cleaned.append((entete, contenu))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f85355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyseAgentWithSummarizer(Agent):\n",
    "    def run(self, inputs):\n",
    "        context = inputs.get(\"context\", \"\").strip()\n",
    "        original_question = inputs.get(\"original_question\", \"\").strip()\n",
    "        reformulated_question = inputs.get(\"reformulated_question\", \"\").strip()\n",
    "        correction_feedback = inputs.get(\"correction_feedback\", \"\").strip()\n",
    "\n",
    "        if not context:\n",
    "            print(\"[Analyse Agent] ‚ö†Ô∏è Contexte vide re√ßu.\")\n",
    "            return {\n",
    "                \"summary\": \"‚ö† Aucun contenu √† r√©sumer.\",\n",
    "                \"extraits_pertinents\": []\n",
    "            }\n",
    "\n",
    "        # D√©coupe les extraits du contexte\n",
    "        extraits = split_context(context)\n",
    "        prompt_extraits = \"\\n\\n\".join(f\"{entete}\\n{contenu}\" for entete, contenu in extraits)\n",
    "\n",
    "        prompt = (\n",
    "            \"Tu es un analyste expert charg√© de synth√©tiser un ou plusieurs documents en fonction de la question pos√©e.\\n\"\n",
    "            \"Tu re√ßois une s√©rie d'extraits de documents (identifi√©s par ent√™te). Pour chaque extrait, il est crucial que tu te concentres sur la **pertinence par rapport √† la question**.\\n\"\n",
    "            \"Ton but est de s√©lectionner uniquement les extraits qui aident √† r√©pondre √† la question pos√©e. Les autres extraits doivent √™tre ignor√©s.\\n\"\n",
    "            \"Commence ta r√©ponse par une **liste brute des extraits pertinents** et indique clairement leur source (document, page, ent√™te). Ensuite, r√©dige une **synth√®se claire et structur√©e** en te basant uniquement sur les extraits retenus.\\n\\n\"\n",
    "            f\"Question originale : {original_question}\\n\"\n",
    "            f\"Question reformul√©e : {reformulated_question}\\n\\n\"\n",
    "            \"Consignes suppl√©mentaires‚ÄØ:\\n\"\n",
    "            \"- Si la question porte sur un aspect sp√©cifique (par exemple, un d√©tail d'un processus), ne garde que les extraits qui r√©pondent directement √† cet aspect.\\n\"\n",
    "            \"- Si la question demande une synth√®se ou une vue d'ensemble, assure-toi de bien couvrir l'int√©gralit√© du sujet sans manquer d'√©l√©ments importants.\\n\"\n",
    "            \"- Exclue toute information qui ne r√©pond pas directement √† la question.\\n\"\n",
    "        )\n",
    "\n",
    "        # Ajout du feedback s'il existe\n",
    "        if correction_feedback:\n",
    "            prompt += f\"\\nIMPORTANT : Prends en compte ce retour pour am√©liorer ta s√©lection ou ta synth√®se :\\n{correction_feedback}\\n\"\n",
    "\n",
    "        prompt += (\n",
    "            f\"\\n=== Extraits √† analyser ===\\n{prompt_extraits}\\n=== Fin des extraits ===\\n\"\n",
    "            \"\\nFORMAT DE R√âPONSE STRICT‚ÄØ:\\n\"\n",
    "            \"```EXTRAITS_PERTINENTS\\n\"\n",
    "            \"Colle ici la liste brute des extraits retenus (un par bloc, sans synth√®se)\\n\"\n",
    "            \"```\\n\"\n",
    "            \"```SYNTH√àSE\\n\"\n",
    "            \"Donne ici la synth√®se claire et structur√©e, bas√©e uniquement sur ces extraits\\n\"\n",
    "            \"```\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        response = llm_local(prompt)\n",
    "\n",
    "        # Extraction auto des deux sections (si bien format√©es)\n",
    "        import re\n",
    "        m_extr = re.search(r\"```EXTRAITS_PERTINENTS\\s*([\\s\\S]+?)```\", response)\n",
    "        m_syn = re.search(r\"```SYNTH√àSE\\s*([\\s\\S]+?)```\", response)\n",
    "        extraits_pertinents = m_extr.group(1).strip() if m_extr else \"\"\n",
    "        synthese = m_syn.group(1).strip() if m_syn else response.strip()\n",
    "\n",
    "        return {\n",
    "            \"summary\": synthese,\n",
    "            \"extraits_pertinents\": extraits_pertinents\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedactionAgentWithPrompt(Agent):\n",
    "    def run(self, inputs):\n",
    "        original_question = inputs.get(\"original_question\", \"\")\n",
    "        reformulated_question = inputs.get(\"reformulated_question\", \"\")\n",
    "        summary = inputs.get(\"summary\", \"\")\n",
    "        context_brut = inputs.get(\"context_brut\", \"\")\n",
    "        extraits_pertinents = inputs.get(\"extraits_pertinents\", \"\")  # <--- NOUVEAU\n",
    "        correction_feedback = inputs.get(\"correction_feedback\", \"\").strip()\n",
    "\n",
    "        # Utilise en priorit√© les extraits pertinents, sinon le r√©sum√©/context_brut\n",
    "        if extraits_pertinents and extraits_pertinents.strip():\n",
    "            base_contexte = extraits_pertinents\n",
    "            contexte_label = \"Extraits pertinents √† utiliser\"\n",
    "        elif context_brut and context_brut.strip():\n",
    "            base_contexte = context_brut\n",
    "            contexte_label = \"Contexte brut √† utiliser\"\n",
    "        elif summary and summary.strip():\n",
    "            base_contexte = summary\n",
    "            contexte_label = \"R√©sum√© synth√©tique √† utiliser\"\n",
    "        else:\n",
    "            return {\"answer\": \"‚ö† Contexte insuffisant pour g√©n√©rer une r√©ponse fiable.\"}\n",
    "\n",
    "        prompt = (\n",
    "            \"Tu es un expert m√©tier. R√©dige une r√©ponse compl√®te, structur√©e et strictement fond√©e sur les extraits pertinents suivants.\\n\\n\"\n",
    "            f\"{contexte_label}‚ÄØ:\\n{base_contexte}\\n\\n\"\n",
    "            f\"R√©sum√© g√©n√©ral pour contexte :\\n{summary}\\n\\n\"\n",
    "            f\"Question originale‚ÄØ: {original_question}\\n\"\n",
    "            f\"Question reformul√©e‚ÄØ: {reformulated_question}\\n\\n\"\n",
    "            \"Consignes importantes :\\n\"\n",
    "            \"- R√©dige une r√©ponse structur√©e (paragraphes ou bullet points si besoin)\\n\"\n",
    "            \"- Chaque information doit √™tre reli√©e √† un extrait, cite la source (ent√™te, page, doc)\\n\"\n",
    "            \"- Si un point n‚Äôest pas pr√©sent dans les extraits, pr√©cise-le honn√™tement\\n\"\n",
    "            \"- N‚Äôinvente rien, ne compl√®te pas hors des extraits\\n\"\n",
    "            \"- Sois factuel, professionnel, pr√©cis\\n\"\n",
    "        )\n",
    "        if correction_feedback:\n",
    "            prompt += f\"\\nIMPORTANT : Prends en compte ce retour pour am√©liorer ta r√©ponse‚ÄØ:\\n{correction_feedback}\\n\"\n",
    "\n",
    "        prompt += \"\\nDonne directement la r√©ponse‚ÄØ:\"\n",
    "\n",
    "        response = llm_local(prompt)\n",
    "        return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationAgent(Agent):\n",
    "    def run(self, inputs):\n",
    "        task_description = inputs.get(\"task_description\", \"\")\n",
    "        output = inputs.get(\"output\", \"\")\n",
    "        original_question = inputs.get(\"original_question\", \"\")\n",
    "        step = inputs.get(\"step\", \"\")  # Ajoute ce champ dans le manager √† chaque √©tape\n",
    "\n",
    "        if step == \"reformulation\":\n",
    "            prompt = (\n",
    "                f\"T√¢che : {task_description}\\n\"\n",
    "                f\"Question d'origine : {original_question}\\n\"\n",
    "                f\"R√©ponse produite : {output}\\n\\n\"\n",
    "                \"V√©rifie les points suivants‚ÄØ:\\n\"\n",
    "                \"- La question est claire et sans faute\\n\"\n",
    "                \"- Elle n'est pas strictement identique √† la question d'origine\\n\"\n",
    "                \"- Elle ne d√©nature pas le sens\\n\"\n",
    "                \"R√©ponds OUI si c'est correct, NON sinon (en expliquant tr√®s bri√®vement pourquoi si NON).\"\n",
    "            )\n",
    "        elif step == \"recherche\":\n",
    "            prompt = (\n",
    "                f\"T√¢che : {task_description}\\n\"\n",
    "                f\"Question : {original_question}\\n\"\n",
    "                f\"Contexte/document trouv√© : {output}\\n\\n\"\n",
    "                \"Valide si le contexte/document trouv√© contient au moins un √©l√©ment pertinent pour r√©pondre √† la question.\"\n",
    "                \"Sinon, r√©ponds NON (explique tr√®s bri√®vement pourquoi).\"\n",
    "            )\n",
    "        elif step == \"analyse\":\n",
    "            prompt = (\n",
    "                f\"T√¢che : {task_description}\\n\"\n",
    "                f\"R√©sum√© produit : {output}\\n\"\n",
    "                f\"Question de d√©part : {original_question}\\n\\n\"\n",
    "                \"Valide si le r√©sum√© synth√©tise r√©ellement les √©l√©ments du contexte, ne se contente pas de g√©n√©ralit√©s, et permet de comprendre la r√©ponse.\\n\"\n",
    "                \"R√©ponds OUI ou NON (en expliquant pourquoi si NON).\"\n",
    "            )\n",
    "        elif step == \"redaction\":\n",
    "            prompt = (\n",
    "                f\"T√¢che : {task_description}\\n\"\n",
    "                f\"R√©ponse finale produite : {output}\\n\"\n",
    "                f\"Question d'origine : {original_question}\\n\\n\"\n",
    "                \"Valide si la r√©ponse est claire, bien r√©dig√©e, sourc√©e (si possible), ne d√©vie pas du contexte fourni.\\n\"\n",
    "                \"R√©ponds OUI ou NON (en expliquant pourquoi si NON).\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"T√¢che : {task_description}\\n\"\n",
    "                f\"Entr√©e : {output}\\n\"\n",
    "                \"Valide uniquement si la sortie correspond √† la t√¢che, sinon NON.\"\n",
    "            )\n",
    "\n",
    "        # Appel LLM\n",
    "        response = llm_local(prompt)\n",
    "        is_valid = \"oui\" in response.lower()\n",
    "        return {\"valid\": is_valid, \"feedback\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcab2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformiteAgent(Agent):\n",
    "    def run(self, inputs):\n",
    "        # Entr√©es attendues :\n",
    "        # - 'documents': liste de dicts [{\"filename\": str, \"content\": str}, ...]\n",
    "        # - 'procedure': texte d√©crivant la proc√©dure ou exigences √† v√©rifier\n",
    "        # - 'user_instruction': consigne ou question utilisateur (\"v√©rifie conformit√©\", etc.)\n",
    "        # - 'correction_feedback' : pour la boucle de correction √©ventuelle\n",
    "\n",
    "        documents = inputs.get(\"documents\", [])\n",
    "        procedure = inputs.get(\"procedure\", \"\")\n",
    "        user_instruction = inputs.get(\"user_instruction\", \"\")\n",
    "        if not user_instruction:\n",
    "            user_instruction = inputs.get(\"original_question\", \"\") or inputs.get(\"question\", \"\")\n",
    "        correction_feedback = inputs.get(\"correction_feedback\", \"\").strip()\n",
    "\n",
    "        # S√©curit√©\n",
    "        if not documents or not procedure:\n",
    "            return {\"conformite\": \"‚ö†Ô∏è Impossible de v√©rifier la conformit√© sans document(s) ET proc√©dure √† comparer.\"}\n",
    "\n",
    "        # Construction du prompt\n",
    "        prompt = (\n",
    "            \"Tu es un expert conformit√© r√©glementaire.\\n\\n\"\n",
    "            f\"Proc√©dure ou exigences √† v√©rifier :\\n{procedure}\\n\\n\"\n",
    "            \"Documents soumis √† l‚Äô√©tude :\\n\"\n",
    "        )\n",
    "        for doc in documents:\n",
    "            prompt += f\"\\n-----\\nNom : {doc.get('filename', 'document')}\\nContenu :\\n{doc.get('content', '')[:1200]}{'...' if len(doc.get('content', '')) > 1200 else ''}\\n\"\n",
    "\n",
    "        prompt += (\n",
    "            f\"\\nConsigne utilisateur : {user_instruction}\\n\"\n",
    "            \"\\n\\n√âvalue pr√©cis√©ment la conformit√© de chaque document vis-√†-vis de la proc√©dure/exigences donn√©es.\\n\"\n",
    "            \"Pour chaque non-conformit√© d√©tect√©e, cite le passage/document concern√© et explique la cause.\"\n",
    "            \"\\nDonne un verdict global‚ÄØ: Conforme / Non conforme. Sois factuel et pr√©cis.\"\n",
    "        )\n",
    "\n",
    "        if correction_feedback:\n",
    "            prompt += f\"\\nIMPORTANT : Prends en compte le(s) retour(s) suivant(s) pour corriger ta r√©ponse :\\n{correction_feedback}\\n\"\n",
    "\n",
    "        # Appel LLM\n",
    "        result = llm_local(prompt)\n",
    "        return {\n",
    "            \"conformite\": result\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheseAgent(Agent):\n",
    "    def run(self, inputs):\n",
    "        \"\"\"\n",
    "        Entr√©es attendues :\n",
    "            - 'documents' : liste de dicts [{\"filename\": str, \"content\": str}, ...]\n",
    "            - 'user_instruction' : string libre (optionnel, par ex. \"r√©sumer\", \"expliquer les points-cl√©s\", etc.)\n",
    "            - 'correction_feedback' : string (retour manager, optionnel)\n",
    "        \"\"\"\n",
    "        documents = inputs.get(\"documents\", [])\n",
    "        user_instruction = inputs.get(\"user_instruction\", \"\")\n",
    "        if not user_instruction:\n",
    "            user_instruction = inputs.get(\"original_question\", \"\") or inputs.get(\"question\", \"\")\n",
    "        correction_feedback = inputs.get(\"correction_feedback\", \"\").strip()\n",
    "\n",
    "        if not documents:\n",
    "            return {\"synthese\": \"‚ö†Ô∏è Aucun document fourni √† synth√©tiser.\"}\n",
    "\n",
    "        prompt = (\n",
    "            \"Tu es un assistant charg√© de lire et de synth√©tiser un ou plusieurs documents pour l'utilisateur.\\n\\n\"\n",
    "            \"Consigne : R√©sume chaque document (ou l'ensemble si c'est coh√©rent), en identifiant les points-cl√©s, les informations essentielles, les parties importantes, et toute sp√©cificit√© qui pourrait int√©resser un professionnel.\\n\"\n",
    "        )\n",
    "        if user_instruction:\n",
    "            prompt += f\"\\nInstruction suppl√©mentaire utilisateur : {user_instruction}\\n\"\n",
    "        prompt += \"\\nDocuments soumis :\\n\"\n",
    "        for doc in documents:\n",
    "            prompt += f\"\\n-----\\nNom : {doc.get('filename','document')}\\nContenu :\\n{doc.get('content','')[:1200]}{'...' if len(doc.get('content','')) > 1200 else ''}\\n\"\n",
    "        if correction_feedback:\n",
    "            prompt += f\"\\nIMPORTANT : Prends en compte le(s) retour(s) suivant(s) pour corriger/am√©liorer ta synth√®se :\\n{correction_feedback}\\n\"\n",
    "\n",
    "        prompt += (\n",
    "            \"\\nTa r√©ponse doit comporter‚ÄØ:\\n\"\n",
    "            \"- Un r√©sum√© global, puis un point par document (s‚Äôil y en a plusieurs)\\n\"\n",
    "            \"- Les notions, proc√©dures, ou passages saillants\\n\"\n",
    "            \"- Si possible, identifie les th√®mes/proc√©dures abord√©s (ex‚ÄØ: conformit√©, technique, RH, etc.)\"\n",
    "        )\n",
    "\n",
    "        # Appel LLM\n",
    "        result = llm_local(prompt)\n",
    "        return {\"synthese\": result}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5deff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExigencesAgent(Agent):\n",
    "    def run(self, inputs):\n",
    "        \"\"\"\n",
    "        Entr√©es attendues :\n",
    "            - 'procedure_context' : str (texte du process/proc√©dure interne r√©cup√©r√©)\n",
    "            - 'user_instruction' : str (optionnel, consigne ou contrainte m√©tier)\n",
    "            - 'correction_feedback' : str (optionnel, feedback du v√©rificateur)\n",
    "        \"\"\"\n",
    "        procedure_context = inputs.get(\"procedure_context\", \"\").strip()\n",
    "        user_instruction = inputs.get(\"user_instruction\", \"\")\n",
    "        if not user_instruction:\n",
    "            user_instruction = inputs.get(\"original_question\", \"\") or inputs.get(\"question\", \"\")\n",
    "        correction_feedback = inputs.get(\"correction_feedback\", \"\").strip()\n",
    "\n",
    "        if not procedure_context:\n",
    "            return {\"exigences\": \"‚ö†Ô∏è Aucun contexte de proc√©dure fourni pour identifier les exigences.\"}\n",
    "\n",
    "        prompt = (\n",
    "            \"Voici un extrait d√©crivant une proc√©dure, une politique, une instruction interne, ou une r√©glementation.\"\n",
    "            \"\\nAnalyse ce texte et identifie clairement toutes les exigences, obligations, mentions l√©gales, √©tapes cl√©s ou conditions n√©cessaires √† la conformit√© du document ou de la proc√©dure.\"\n",
    "        )\n",
    "        if user_instruction:\n",
    "            prompt += f\"\\nContrainte suppl√©mentaire √† prendre en compte : {user_instruction}\"\n",
    "        if correction_feedback:\n",
    "            prompt += f\"\\nIMPORTANT : Corrige selon ce feedback : {correction_feedback}\"\n",
    "\n",
    "        prompt += (\n",
    "            f\"\\n\\n=== Proc√©dure √† analyser ===\\n{procedure_context[:2000]}\"\n",
    "            f\"{'...' if len(procedure_context) > 2000 else ''}\\n\"\n",
    "        )\n",
    "        prompt += (\n",
    "            \"\\nR√©ponds uniquement sous forme de liste‚ÄØ:\"\n",
    "            \"\\n- Chaque exigence sous forme d‚Äôune phrase claire et concise\"\n",
    "            \"\\n- Num√©rote si possible (1., 2., ...)\"\n",
    "            \"\\n- Si aucune exigence n‚Äôest trouv√©e, indique-le explicitement.\"\n",
    "        )\n",
    "\n",
    "        result = llm_local(prompt)\n",
    "        # S√©curise la sortie : ne jamais bloquer le pipeline\n",
    "        if not result or not result.strip():\n",
    "            result = \"Aucune exigence trouv√©e dans la proc√©dure.\"\n",
    "        return {\"exigences\": result}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentificationProcedureAgent(Agent):\n",
    "    def run(self, inputs):\n",
    "        synthese = inputs.get(\"synthese\", \"\")\n",
    "        user_instruction = inputs.get(\"user_instruction\", \"\")\n",
    "        # Tu peux aussi passer les documents si tu veux regarder les titres, etc.\n",
    "\n",
    "        prompt = (\n",
    "            \"Lis la synth√®se/document ci-dessous et, en fonction du texte ET de la consigne utilisateur, \"\n",
    "            \"identifie la proc√©dure ou le standard interne (banque, assurance, RH, etc.) auquel il doit √™tre compar√©. \"\n",
    "            \"Donne uniquement le nom/type de proc√©dure √† rechercher (ex‚ÄØ: 'Ouverture de compte', 'Proc√©dure KYC', 'Mise √† jour dossier client', etc.).\\n\"\n",
    "            f\"Synth√®se/document‚ÄØ:\\n{synthese}\\n\"\n",
    "            f\"Consigne utilisateur‚ÄØ: {user_instruction}\\n\"\n",
    "            \"R√©ponds par une courte phrase du type‚ÄØ: 'Proc√©dure √† rechercher‚ÄØ: ...'\"\n",
    "        )\n",
    "        return {\"procedure_a_rechercher\": llm_local(prompt)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f5da7",
   "metadata": {},
   "source": [
    "### instanciation denos agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation des agents CrewAI\n",
    "agent_reception = ReceptionAgentReformulator(\n",
    "    name=\"idir l'acceuil\",\n",
    "    role=\"Reformule la question uniquement en fran√ßais.\",\n",
    "    goal=\"Comprendre l‚Äôintention de l‚Äôutilisateur et reformuler la question de fa√ßon claire et pr√©cise uniquement en fran√ßais.\",\n",
    "    backstory=\"Expert NLP.\",\n",
    "    verbose=False,\n",
    "    llm=llm_local\n",
    ")\n",
    "\n",
    "# 1. Cr√©e les retriever_agents par domaine\n",
    "retriever_agents = {}\n",
    "for domain in indices.keys():\n",
    "    retriever_agents[domain] = RetrieverAgent(\n",
    "        model=model,\n",
    "        index=indices[domain],\n",
    "        nlp=nlp,\n",
    "        indexed_chunks=chunks[domain],\n",
    "        reranker_model=reranker_model,\n",
    "        reranker_tokenizer=reranker_tokenizer\n",
    "    )\n",
    "\n",
    "# 2. Cr√©e les agents de recherche par domaine\n",
    "recherche_agents = {}\n",
    "for domain in retriever_agents.keys():\n",
    "    agent = RechercheAgentWithRetriever(\n",
    "        retriever_agent=retriever_agents[domain],\n",
    "        name=f\"chercheur_{domain}\",\n",
    "        role=f\"Recherche des documents pour le domaine {domain}\",\n",
    "        goal=\"Trouver les documents les plus pertinents pour le domaine \" + domain,\n",
    "        backstory=\"Expert documentaire.\",\n",
    "        verbose=False,\n",
    "        llm=llm_local\n",
    "    )\n",
    "    recherche_agents[domain] = agent\n",
    "\n",
    "agent_analyse = AnalyseAgentWithSummarizer(\n",
    "    name=\"yasmina l'analyste\",\n",
    "    role=\"Filtre, s√©lectionne et synth√©tise les extraits pertinents issus des documents, uniquement en fran√ßais.\",\n",
    "    goal=(\n",
    "        \"Parmi tous les extraits issus des documents, s√©lectionner ceux qui sont directement pertinents pour la question, \"\n",
    "        \"et produire une synth√®se claire, structur√©e, en citant les extraits utiles. \"\n",
    "        \"La synth√®se doit √™tre exhaustive, fid√®le et uniquement bas√©e sur les extraits s√©lectionn√©s.\"\n",
    "    ),\n",
    "    backstory=(\n",
    "        \"Analyste documentaire senior, sp√©cialis√© dans la synth√®se experte de corpus volumineux. \"\n",
    "        \"Ton expertise est d‚Äôidentifier l‚Äôinformation critique dans des ensembles de documents et de la restituer \"\n",
    "        \"de mani√®re structur√©e et fiable pour des utilisateurs exigeants (banque, juridique, data science).\"\n",
    "    ),\n",
    "    verbose=False,\n",
    "    llm=llm_local\n",
    ")\n",
    "\n",
    "agent_redaction = RedactionAgentWithPrompt(\n",
    "    name=\"nihad la r√©dactrice\",\n",
    "    role=\"R√©dige une r√©ponse claire et sourc√©e uniquement en fran√ßais.\",\n",
    "    goal=\"Produire une r√©ponse claire et sourc√©e bas√©e sur le contexte fourni uniquement en fran√ßais.\",\n",
    "    backstory=\"Assistant IA sp√©cialis√©.\",\n",
    "    verbose=False,\n",
    "    llm=llm_local\n",
    ")\n",
    "\n",
    "agent_verificateur = VerificationAgent(\n",
    "    name=\"Kenza la v√©rificatrice\",\n",
    "    role=\"V√©rifie si l‚Äôagent a bien accompli sa t√¢che.\",\n",
    "    goal=\"Assurer la conformit√© de chaque t√¢che agent avec la consigne donn√©e.\",\n",
    "    backstory=\"Auditeur IA expert.\",\n",
    "    verbose=False,\n",
    "    llm=llm_local\n",
    ")\n",
    "\n",
    "exigences_agent = ExigencesAgent(\n",
    "    name=\"Agent Exigences\",\n",
    "    role=\"Identifie et extrait les exigences (r√®gles, obligations, √©tapes‚Ä¶) √† partir d‚Äôune proc√©dure interne ou d‚Äôun standard.\",\n",
    "    goal=\"Analyser le texte d‚Äôune proc√©dure ou d‚Äôune politique interne pour extraire la liste pr√©cise des exigences √† respecter.\",\n",
    "    backstory=\"Expert conformit√© et analyse r√©glementaire.\",\n",
    "    verbose=False,    # Debug d√©sactiv√©\n",
    "    llm=llm_local     # Ton instance LLM (locale ou API)\n",
    ")\n",
    "\n",
    "synthese_agent = SyntheseAgent(\n",
    "    name=\"Agent Synth√®se\",\n",
    "    role=\"Analyse et synth√©tise des documents import√©s.\",\n",
    "    goal=\"Lire un ou plusieurs documents fournis par l‚Äôutilisateur et produire un r√©sum√© structur√©, des points-cl√©s et, si besoin, des extraits.\",\n",
    "    backstory=\"Assistant IA exp√©riment√© en lecture rapide et extraction d‚Äôinformations.\",\n",
    "    verbose=False,   # On d√©sactive le debug/print\n",
    "    llm=llm_local    # Ton instance/handle de LLM locale ou API\n",
    ")\n",
    "\n",
    "conformite_agent = ConformiteAgent(\n",
    "    name=\"Agent Conformit√©\",\n",
    "    role=\"V√©rifie la conformit√© documentaire/proc√©durale.\",\n",
    "    goal=\"Analyser les documents import√©s et v√©rifier leur conformit√© avec les proc√©dures internes.\",\n",
    "    backstory=\"Expert conformit√© r√©glementaire.\",\n",
    "    verbose=False,  # D√©sactive le mode bavard en prod\n",
    "    llm=llm_local\n",
    ")\n",
    "\n",
    "agent_identification_procedure = IdentificationProcedureAgent(\n",
    "    name=\"Detecteur de Proc√©dure\",\n",
    "    role=\"D√©tecte la proc√©dure ou le standard √† v√©rifier √† partir des documents import√©s.\",\n",
    "    goal=\"Analyser le document et la consigne utilisateur pour d√©terminer la proc√©dure de r√©f√©rence.\",\n",
    "    backstory=\"Assistant IA sp√©cialis√© dans l‚Äôorientation des requ√™tes conformit√©.\",\n",
    "    verbose=False,\n",
    "    llm=llm_local\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPCAgent(Agent):\n",
    "    def run(self, inputs):\n",
    "        # On pr√©f√®re \"original_question\" pour garder la logique globale\n",
    "        question = inputs.get(\"original_question\", \"\") or inputs.get(\"question\", \"\")\n",
    "        documents = inputs.get(\"documents\", [])\n",
    "        domains = inputs.get(\"domains\", [])\n",
    "        doc_names = [doc.get(\"filename\", \"doc\") for doc in documents][:3]\n",
    "        doc_info = \", \".join(doc_names) if doc_names else \"aucun\"\n",
    "\n",
    "        prompt = (\n",
    "            \"Tu es l'agent chef d‚Äôorchestre d‚Äôun assistant IA multi-agent.\\n\"\n",
    "            \"√Ä chaque question, tu dois D√âCIDER la pipeline la plus adapt√©e, en expliquant ton choix.\\n\"\n",
    "            \"Tu dois TOUJOURS r√©pondre en JSON STRICT.\\n\"\n",
    "            \"Tu as 4 pipelines possibles‚ÄØ:\\n\"\n",
    "            \"- 'rag'‚ÄØ: Recherche interne uniquement (pas de documents import√©s)\\n\"\n",
    "            \"- 'explication'‚ÄØ: Explication/synth√®se de documents import√©s (l'utilisateur veut qu‚Äôon explique ou analyse ses fichiers)\\n\"\n",
    "            \"- 'conformite'‚ÄØ: V√©rification de conformit√© des docs import√©s vs une proc√©dure\\n\"\n",
    "            \"- 'mixte'‚ÄØ: Croisement des infos docs import√©s + base interne (si la question le demande)\\n\"\n",
    "            \"\\nRends TOUJOURS une r√©ponse JSON au format‚ÄØ:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"pipeline\\\": \\\"rag|explication|conformite|mixte\\\",\\n\"\n",
    "            \"  \\\"domaine\\\": \\\"...\\\",\\n\"\n",
    "            \"  \\\"need_reformulation\\\": true|false,\\n\"\n",
    "            \"  \\\"steps_plan\\\": [\\\"√©tape1\\\", \\\"√©tape2\\\", ...],\\n\"\n",
    "            \"  \\\"feedback\\\": \\\"explique pourquoi ce choix, mentionne les indices dans la question ou la pr√©sence/absence de documents\\\"\\n\"\n",
    "            \"}\\n\"\n",
    "            \"Exemples‚ÄØ:\\n\"\n",
    "            \"- question‚ÄØ: 'explique ces documents', docs OUI ‚Üí pipeline='explication'\\n\"\n",
    "            \"- question‚ÄØ: 'v√©rifie la conformit√©', docs OUI ‚Üí pipeline='conformite'\\n\"\n",
    "            \"- question‚ÄØ: 'donne la proc√©dure X', docs NON ‚Üí pipeline='rag'\\n\"\n",
    "            \"- question‚ÄØ: 'croise ce doc avec la base', docs OUI ‚Üí pipeline='mixte'\\n\"\n",
    "            \"\\nINPUTS‚ÄØ:\\n\"\n",
    "            f\"- Question : {question}\\n\"\n",
    "            f\"- Docs import√©s ({len(documents)}) : {doc_info}\\n\"\n",
    "            f\"- Domaines disponibles : {', '.join(domains)}\\n\"\n",
    "        )\n",
    "\n",
    "        result_str = llm_local(prompt)\n",
    "        import json, re\n",
    "        # Essaye de parser proprement le JSON\n",
    "        try:\n",
    "            result_json_str = re.search(r\"\\{.*\\}\", result_str, re.DOTALL).group(0)\n",
    "            result = json.loads(result_json_str)\n",
    "        except Exception:\n",
    "            # Fallback (pour √©viter le crash)\n",
    "            result = {\n",
    "                \"pipeline\": \"rag\",\n",
    "                \"domaine\": domains[0] if domains else \"g√©n√©ral\",\n",
    "                \"need_reformulation\": True,\n",
    "                \"steps_plan\": [],\n",
    "                \"feedback\": \"Fallback: parsing √©chou√©, prompt non respect√©.\"\n",
    "            }\n",
    "        # S√©curise les champs\n",
    "        result[\"pipeline\"] = result.get(\"pipeline\", \"rag\")\n",
    "        result[\"domaine\"] = result.get(\"domaine\", domains[0] if domains else \"g√©n√©ral\")\n",
    "        result[\"need_reformulation\"] = (\n",
    "            str(result.get(\"need_reformulation\", \"True\")).strip().lower() in [\"true\", \"oui\", \"yes\"]\n",
    "        )\n",
    "        result[\"steps_plan\"] = result.get(\"steps_plan\", [])\n",
    "        result[\"feedback\"] = result.get(\"feedback\", \"RAS\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2dbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_mpc = MPCAgent(\n",
    "    name=\"Samy le MPC\",\n",
    "    role=\"Oriente la question, choisit le domaine pertinent et la strat√©gie.\",\n",
    "    goal=\"Analyser la question pour choisir le bon domaine et le flux optimal.\",\n",
    "    backstory=\"Orchestrateur intelligent, expert du contexte m√©tier.\",\n",
    "    verbose=False,\n",
    "    llm=llm_local\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d92b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reformulation(text):\n",
    "    m = re.search(r'[\"‚Äú¬´]([^\"‚Äù¬ª]+)[\"‚Äù¬ª]', text)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    if \":\" in text:\n",
    "        last = text.split(\":\")[-1].strip()\n",
    "        return last if last else text.strip()\n",
    "    return text.strip()\n",
    "\n",
    "def extract_context(text):\n",
    "    return text.strip()\n",
    "\n",
    "def extract_summary(text):\n",
    "    return text.strip()\n",
    "\n",
    "def extract_answer(text):\n",
    "    return text.strip()\n",
    "\n",
    "def is_acceptable_reformulation(original, reformulated):\n",
    "    # Consid√®re acceptable si ce n'est pas strictement identique et pas vide\n",
    "    if not reformulated or not original:\n",
    "        return False\n",
    "    return reformulated.strip().lower() != original.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb281997",
   "metadata": {},
   "source": [
    "### mis en plage de l'orchestrateur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentManager:\n",
    "    def __init__(self, agents, agent_verif, agent_mpc, recherche_agents, domains, max_retries=2):\n",
    "\n",
    "        self.agents = agents\n",
    "        self.agent_verif = agent_verif\n",
    "        self.agent_mpc = agent_mpc\n",
    "        self.recherche_agents = recherche_agents\n",
    "        self.domains = domains\n",
    "        self.max_retries = max_retries\n",
    "        self.log_steps = []\n",
    "\n",
    "    def log(self, msg):\n",
    "        # Tu peux simplement passer si tu ne veux pas de logs\n",
    "        pass\n",
    "\n",
    "    def safe_agent_run(self, agent, input_dict, task_description, user_question, extractor, step):\n",
    "        feedback = \"\"\n",
    "        agent_output = None\n",
    "        verif = None\n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            if feedback:\n",
    "                input_dict['correction_feedback'] = feedback\n",
    "            agent_output = agent.run(input_dict)\n",
    "            if isinstance(agent_output, dict):\n",
    "                value = next((v for v in agent_output.values() if isinstance(v, str) and v.strip()), \"\")\n",
    "            else:\n",
    "                value = str(agent_output)\n",
    "            extracted = extractor(value)\n",
    "            verif_input = {\n",
    "                \"task_description\": task_description + (f\" (Corrige selon feedback : {feedback})\" if feedback else \"\"),\n",
    "                \"output\": extracted,\n",
    "                \"original_question\": user_question,\n",
    "                \"step\": step\n",
    "            }\n",
    "            verif = self.agent_verif.run(verif_input)\n",
    "            valid = verif.get('valid', False)\n",
    "            self.log(\n",
    "                f\"Essai {attempt+1} / {self.max_retries+1} pour {task_description} : valid={valid}\\nFeedback: {verif.get('feedback','')}\\nR√©ponse candidate: {repr(extracted)}\"\n",
    "            )\n",
    "            if valid:\n",
    "                return extracted, verif, attempt + 1\n",
    "            feedback = verif.get('feedback', \"\")\n",
    "        return extracted, verif, self.max_retries + 1\n",
    "\n",
    "    def run_pipeline(self, user_question, documents=None, user_instruction=None):\n",
    "        \"\"\"\n",
    "        user_question : str\n",
    "        documents : list de dicts [{\"filename\":..., \"content\":...}], optionnel\n",
    "        \"\"\"\n",
    "        # --- Initialisation du r√©sultat global\n",
    "        result = {\n",
    "            \"mpc_decision\": {},\n",
    "            \"pipeline\": \"\",\n",
    "            \"domaine\": \"\",\n",
    "            \"need_reformulation\": False,\n",
    "            \"steps_plan\": [],\n",
    "            \"feedback_mpc\": \"\",\n",
    "            \"reformulation\": \"\",\n",
    "            \"context\": \"\",\n",
    "            \"summary\": \"\",\n",
    "            \"answer\": \"\",\n",
    "            \"exigences\": \"\",\n",
    "            \"conformite\": \"\",\n",
    "            \"verification\": [],\n",
    "            \"success\": False,\n",
    "            \"attempts\": 0,\n",
    "            \"reason\": \"\",\n",
    "        }\n",
    "\n",
    "        # ==== 1. Appel MPC ====\n",
    "        mpc_inputs = {\n",
    "            \"original_question\": user_question,\n",
    "            \"documents\": documents if documents else [],\n",
    "            \"domains\": self.domains\n",
    "        }\n",
    "        mpc_result = self.agent_mpc.run(mpc_inputs) or {}\n",
    "\n",
    "        # Extraction (avec fallback par d√©faut)\n",
    "        pipeline = mpc_result.get(\"pipeline\", \"rag\")\n",
    "        domaine = mpc_result.get(\"domaine\", self.domains[0] if self.domains else \"g√©n√©ral\")\n",
    "        need_reformulation = mpc_result.get(\"need_reformulation\", True)\n",
    "        steps_plan = mpc_result.get(\"steps_plan\", [])\n",
    "        feedback_mpc = mpc_result.get(\"feedback\", \"\")\n",
    "\n",
    "        # Stocke tout dans le r√©sultat global\n",
    "        result[\"mpc_decision\"] = mpc_result\n",
    "        result[\"pipeline\"] = pipeline\n",
    "        result[\"domaine\"] = domaine\n",
    "        result[\"need_reformulation\"] = need_reformulation\n",
    "        result[\"steps_plan\"] = steps_plan\n",
    "        result[\"feedback_mpc\"] = feedback_mpc\n",
    "\n",
    "        reformulation = user_question\n",
    "        n_attempts_reform = 1\n",
    "        verif_reform = {\"valid\": True, \"feedback\": \"\"}\n",
    "        if need_reformulation:\n",
    "            # On pr√©pare l'input pour l'agent reception/reformulateur\n",
    "            reform_input = {\n",
    "            \"input\": user_question\n",
    "            }\n",
    "            # Appel de l'agent de reformulation\n",
    "            reformulation_result = self.agents[\"reception\"].run(reform_input)\n",
    "            # Essaye de r√©cup√©rer la question reformul√©e selon ton agent\n",
    "            if isinstance(reformulation_result, dict) and \"reformulated_question\" in reformulation_result:\n",
    "                candidate = reformulation_result[\"reformulated_question\"]\n",
    "                # Optionnel : si agent v√©rificateur, le passer ici aussi pour valider la reformulation\n",
    "                verif_input = {\n",
    "                    \"task_description\": \"V√©rifie la qualit√© de la reformulation.\",\n",
    "                    \"output\": candidate,\n",
    "                    \"original_question\": user_question,\n",
    "                    \"step\": \"reformulation\"\n",
    "                }\n",
    "                verif_reform = self.agent_verif.run(verif_input)\n",
    "                # Si la reformulation est vide ou trop proche de l'original, fallback sur l'original\n",
    "                if not verif_reform.get(\"valid\", False):\n",
    "                    from difflib import SequenceMatcher\n",
    "                    similarity = SequenceMatcher(None, candidate, user_question).ratio()\n",
    "                    if similarity > 0.95 or not candidate.strip():\n",
    "                        reformulation = user_question  # on garde l'original\n",
    "                        verif_reform[\"feedback\"] = verif_reform.get(\"feedback\", \"\") + \" (Reformulation ignor√©e, trop similaire ou vide)\"\n",
    "                    else:\n",
    "                        reformulation = candidate\n",
    "                else:\n",
    "                    reformulation = candidate\n",
    "            else:\n",
    "                reformulation = user_question  # fallback\n",
    "\n",
    "        # Ajoute au r√©sultat global\n",
    "        result[\"reformulation\"] = reformulation\n",
    "        result[\"verification\"].append({\n",
    "            \"step\": \"reformulation\",\n",
    "            \"feedback\": verif_reform.get(\"feedback\", \"\"),\n",
    "            \"valid\": verif_reform.get(\"valid\", True),\n",
    "            \"attempts\": n_attempts_reform\n",
    "        })\n",
    "\n",
    "            # === 3. S√©lection pipeline selon la d√©cision de l‚Äôagent MPC ===\n",
    "        pipeline_type = mpc_result.get(\"pipeline\", \"rag\").lower()  # par d√©faut \"rag\"\n",
    "        domain = mpc_result.get(\"domaine\", self.domains[0])\n",
    "        agent_recherche = self.recherche_agents.get(domain) or next(iter(self.recherche_agents.values()))\n",
    "        # (On peut g√©rer d'autres variables issues du MPC si besoin)\n",
    "\n",
    "        if pipeline_type == \"rag\":\n",
    "            # -- 2. Recherche documentaire (pipeline RAG classique)\n",
    "            context, verif_search, n_attempts_search = self.safe_agent_run(\n",
    "                agent_recherche,\n",
    "                {\n",
    "                    \"original_question\": user_question,\n",
    "                    \"reformulated_question\": reformulation\n",
    "                },\n",
    "                f\"Trouve les documents pertinents pour r√©pondre √† la question dans le domaine {domain}.\",\n",
    "                user_question,\n",
    "                extract_context,\n",
    "                \"recherche\"\n",
    "            )\n",
    "            result[\"context\"] = context\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"recherche\",\n",
    "                \"feedback\": verif_search.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_search.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_search\n",
    "            })\n",
    "            # Pas de blocage si pas de contexte pertinent\n",
    "            if not verif_search.get(\"valid\", False) or not context.strip():\n",
    "                result[\"reason\"] = f\"Aucun contexte/document pertinent trouv√© ou blocage v√©rificateur apr√®s {n_attempts_search} essais : {verif_search.get('feedback', '')}\"\n",
    "\n",
    "            # -- 3. Analyse/synth√®se des extraits\n",
    "            summary, verif_analyse, n_attempts_analyse = self.safe_agent_run(\n",
    "                self.agents[\"analyse\"],\n",
    "                {\n",
    "                    \"context\": context,\n",
    "                    \"original_question\": user_question,\n",
    "                    \"reformulated_question\": reformulation\n",
    "                },\n",
    "                \"Synth√©tise et r√©sume les √©l√©ments pertinents des documents trouv√©s pour r√©pondre √† la question.\",\n",
    "                user_question,\n",
    "                extract_summary,\n",
    "                \"analyse\"\n",
    "            )\n",
    "            result[\"summary\"] = summary\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"analyse\",\n",
    "                \"feedback\": verif_analyse.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_analyse.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_analyse\n",
    "            })\n",
    "            # Toujours continuer m√™me si le r√©sum√© n‚Äôest pas parfait\n",
    "\n",
    "            # -- 4. R√©daction finale\n",
    "            answer, verif_redac, n_attempts_redac = self.safe_agent_run(\n",
    "                self.agents[\"redaction\"],\n",
    "                {\n",
    "                    \"original_question\": user_question,\n",
    "                    \"reformulated_question\": reformulation,\n",
    "                    \"summary\": summary,\n",
    "                    \"context_brut\": context\n",
    "                },\n",
    "                \"R√©dige une r√©ponse claire, pr√©cise et sourc√©e, uniquement en fran√ßais, sur la base du r√©sum√© fourni.\",\n",
    "                user_question,\n",
    "                extract_answer,\n",
    "                \"redaction\"\n",
    "            )\n",
    "            result[\"answer\"] = answer\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"redaction\",\n",
    "                \"feedback\": verif_redac.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_redac.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_redac\n",
    "            })\n",
    "            # M√™me en cas d'√©chec, la pipeline va jusqu‚Äôau bout, pas de blocage\n",
    "\n",
    "            # -- Statut global et message final\n",
    "            result[\"success\"] = True\n",
    "            result[\"attempts\"] = n_attempts_reform + n_attempts_search + n_attempts_analyse + n_attempts_redac\n",
    "            result[\"reason\"] = result.get(\"reason\", \"Pipeline RAG ex√©cut√©e (avec ou sans blocage).\")\n",
    "\n",
    "        elif pipeline_type == \"conformite\":\n",
    "            # 1. Lecture/Synth√®se des documents import√©s\n",
    "            synthese, verif_synth, n_attempts_synth = self.safe_agent_run(\n",
    "                self.agents[\"synthese\"],  # <-- Ajoute-le bien √† self.agents lors de l'instanciation du manager\n",
    "                {\n",
    "                    \"documents\": documents,  # tu dois faire passer la liste de dicts ici\n",
    "                    \"user_instruction\": user_question  # l'instruction pos√©e dans la barre\n",
    "                },\n",
    "                \"Fais une synth√®se structur√©e des documents import√©s.\",\n",
    "                user_question,\n",
    "                lambda x: x,  # Pas d'extracteur sp√©cifique, r√©sultat d√©j√† dict avec \"synthese\"\n",
    "                \"synthese\"\n",
    "            )\n",
    "            result[\"synthese\"] = synthese\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"synthese\",\n",
    "                \"feedback\": verif_synth.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_synth.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_synth\n",
    "            })\n",
    "\n",
    "            # 2. Recherche/extraction de la proc√©dure ou des exigences\n",
    "            # Ici, tu peux utiliser un agent Recherche sur un domaine pr√©cis, ou un agent Exigences d√©di√©\n",
    "            procedure_context = \"\"  # √† remplir selon comment tu trouves la proc√©dure (ex via agent recherche ou user input)\n",
    "            exigences = \"\"\n",
    "            if \"agent_exigences\" in self.agents:\n",
    "                exigences, verif_exig, n_attempts_exig = self.safe_agent_run(\n",
    "                    self.agents[\"exigences\"],\n",
    "                    {\n",
    "                        \"procedure_context\": procedure_context,  # Met ici le texte √† analyser !\n",
    "                        \"user_instruction\": user_question\n",
    "                    },\n",
    "                    \"Identifie toutes les exigences √† respecter pour la proc√©dure.\",\n",
    "                    user_question,\n",
    "                    lambda x: x,\n",
    "                    \"exigences\"\n",
    "                )\n",
    "                result[\"exigences\"] = exigences\n",
    "                result[\"verification\"].append({\n",
    "                    \"step\": \"exigences\",\n",
    "                    \"feedback\": verif_exig.get(\"feedback\", \"\"),\n",
    "                    \"valid\": verif_exig.get(\"valid\", False),\n",
    "                    \"attempts\": n_attempts_exig\n",
    "                })\n",
    "            else:\n",
    "                # Cas o√π pas d'agent exigences, tu peux chercher via agent_recherche sur \"proc√©dures\"\n",
    "                pass\n",
    "\n",
    "            # 3. V√©rification de conformit√© proprement dite\n",
    "            conformite, verif_conf, n_attempts_conf = self.safe_agent_run(\n",
    "                self.agents[\"conformite\"],\n",
    "                {\n",
    "                    \"documents\": documents,\n",
    "                    \"procedure\": exigences if exigences else procedure_context,\n",
    "                    \"user_instruction\": user_question\n",
    "                },\n",
    "                \"V√©rifie la conformit√© des documents import√©s vis-√†-vis des exigences/processus internes.\",\n",
    "                user_question,\n",
    "                lambda x: x,\n",
    "                \"conformite\"\n",
    "            )\n",
    "            result[\"conformite\"] = conformite\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"conformite\",\n",
    "                \"feedback\": verif_conf.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_conf.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_conf\n",
    "            })\n",
    "\n",
    "            # 4. R√©daction finale (sur le retour conformit√©, ou synth√®se‚Ä¶)\n",
    "            answer, verif_redac, n_attempts_redac = self.safe_agent_run(\n",
    "                self.agents[\"redaction\"],\n",
    "                {\n",
    "                    \"original_question\": user_question,\n",
    "                    \"summary\": synthese,\n",
    "                    \"context_brut\": str(conformite),\n",
    "                    \"extraits_pertinents\": \"\",  # Optionnel si besoin\n",
    "                },\n",
    "                \"R√©dige un rapport clair et factuel sur la conformit√© des documents.\",\n",
    "                user_question,\n",
    "                extract_answer,\n",
    "                \"redaction\"\n",
    "            )\n",
    "            result[\"answer\"] = answer\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"redaction\",\n",
    "                \"feedback\": verif_redac.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_redac.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_redac\n",
    "            })\n",
    "\n",
    "            result[\"success\"] = True\n",
    "            result[\"attempts\"] = n_attempts_synth + (n_attempts_exig if \"agent_exigences\" in self.agents else 0) + n_attempts_conf + n_attempts_redac\n",
    "            result[\"reason\"] = result.get(\"reason\", \"Pipeline conformit√© ex√©cut√©e.\")\n",
    "        \n",
    "        elif pipeline_type == \"explication\":\n",
    "            # 1. Synth√®se ou lecture des documents (si pr√©sents)\n",
    "            if documents:\n",
    "                synthese, verif_synth, n_attempts_synth = self.safe_agent_run(\n",
    "                    self.agents[\"synthese\"],\n",
    "                    {\n",
    "                        \"documents\": documents,\n",
    "                        \"user_instruction\": user_question  # tu passes l‚Äôinstruction telle quelle\n",
    "                    },\n",
    "                    \"Fais une synth√®se/lecture des documents import√©s pour fournir du contexte √† l'explication.\",\n",
    "                    user_question,\n",
    "                    lambda x: x,\n",
    "                    \"synthese\"\n",
    "                )\n",
    "                base_context = synthese\n",
    "                result[\"synthese\"] = synthese\n",
    "                result[\"verification\"].append({\n",
    "                    \"step\": \"synthese\",\n",
    "                    \"feedback\": verif_synth.get(\"feedback\", \"\"),\n",
    "                    \"valid\": verif_synth.get(\"valid\", False),\n",
    "                    \"attempts\": n_attempts_synth\n",
    "                })\n",
    "            else:\n",
    "                base_context = \"\"\n",
    "\n",
    "            # 2. Agent \"explication\" (tu peux soit d√©dier un agent, soit utiliser l'agent analyse avec un prompt sp√©cifique)\n",
    "            # Si tu veux un agent d√©di√©¬†:\n",
    "            if \"explication\" in self.agents:\n",
    "                explication, verif_expl, n_attempts_expl = self.safe_agent_run(\n",
    "                    self.agents[\"explication\"],\n",
    "                    {\n",
    "                        \"context\": base_context,\n",
    "                        \"user_instruction\": user_question\n",
    "                    },\n",
    "                    \"Fournis une explication d√©taill√©e sur la notion ou la question pos√©e.\",\n",
    "                    user_question,\n",
    "                    lambda x: x,\n",
    "                    \"explication\"\n",
    "                )\n",
    "                result[\"explication\"] = explication\n",
    "                result[\"verification\"].append({\n",
    "                    \"step\": \"explication\",\n",
    "                    \"feedback\": verif_expl.get(\"feedback\", \"\"),\n",
    "                    \"valid\": verif_expl.get(\"valid\", False),\n",
    "                    \"attempts\": n_attempts_expl\n",
    "                })\n",
    "            else:\n",
    "                # Sinon, fallback sur agent analyse g√©n√©rique\n",
    "                explication, verif_expl, n_attempts_expl = self.safe_agent_run(\n",
    "                    self.agents[\"analyse\"],\n",
    "                    {\n",
    "                        \"context\": base_context,\n",
    "                        \"original_question\": user_question,\n",
    "                        \"reformulated_question\": user_question  # tu peux passer l‚Äôoriginal si pas reformul√©e\n",
    "                    },\n",
    "                    \"Explique la notion demand√©e, en s'appuyant sur les documents import√©s si pr√©sents.\",\n",
    "                    user_question,\n",
    "                    lambda x: x,\n",
    "                    \"explication\"\n",
    "                )\n",
    "                result[\"explication\"] = explication\n",
    "                result[\"verification\"].append({\n",
    "                    \"step\": \"explication\",\n",
    "                    \"feedback\": verif_expl.get(\"feedback\", \"\"),\n",
    "                    \"valid\": verif_expl.get(\"valid\", False),\n",
    "                    \"attempts\": n_attempts_expl\n",
    "                })\n",
    "\n",
    "            # 3. R√©daction finale\n",
    "            answer, verif_redac, n_attempts_redac = self.safe_agent_run(\n",
    "                self.agents[\"redaction\"],\n",
    "                {\n",
    "                    \"original_question\": user_question,\n",
    "                    \"summary\": base_context,\n",
    "                    \"context_brut\": result[\"explication\"],\n",
    "                    \"extraits_pertinents\": \"\",  # ou tu peux y mettre un extrait cl√©, selon ton output agent explication\n",
    "                },\n",
    "                \"R√©dige une explication claire, pr√©cise et p√©dagogique bas√©e sur l'analyse pr√©c√©dente.\",\n",
    "                user_question,\n",
    "                extract_answer,\n",
    "                \"redaction\"\n",
    "            )\n",
    "            result[\"answer\"] = answer\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"redaction\",\n",
    "                \"feedback\": verif_redac.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_redac.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_redac\n",
    "            })\n",
    "\n",
    "            result[\"success\"] = True\n",
    "            result[\"attempts\"] = (n_attempts_synth if documents else 0) + n_attempts_expl + n_attempts_redac\n",
    "            result[\"reason\"] = result.get(\"reason\", \"Pipeline explication ex√©cut√©e.\")\n",
    "\n",
    "        elif pipeline_type == \"mixte\":\n",
    "            # 1. Synth√®se/lecture des documents import√©s\n",
    "            if documents:\n",
    "                synthese, verif_synth, n_attempts_synth = self.safe_agent_run(\n",
    "                    self.agents[\"synthese\"],\n",
    "                    {\n",
    "                        \"documents\": documents,\n",
    "                        \"user_instruction\": user_question\n",
    "                    },\n",
    "                    \"Lis et synth√©tise le(s) document(s) import√©(s) pour pr√©parer la r√©ponse.\",\n",
    "                    user_question,\n",
    "                    lambda x: x,\n",
    "                    \"synthese\"\n",
    "                )\n",
    "                base_doc_context = synthese\n",
    "                result[\"synthese\"] = synthese\n",
    "                result[\"verification\"].append({\n",
    "                    \"step\": \"synthese\",\n",
    "                    \"feedback\": verif_synth.get(\"feedback\", \"\"),\n",
    "                    \"valid\": verif_synth.get(\"valid\", False),\n",
    "                    \"attempts\": n_attempts_synth\n",
    "                })\n",
    "            else:\n",
    "                base_doc_context = \"\"\n",
    "\n",
    "            # 2. Recherche documentaire RAG (base interne, domaine choisi par MPC)\n",
    "            context, verif_search, n_attempts_search = self.safe_agent_run(\n",
    "                agent_recherche,\n",
    "                {\n",
    "                    \"original_question\": user_question,\n",
    "                    \"reformulated_question\": reformulation\n",
    "                },\n",
    "                f\"Trouve les documents internes pertinents pour r√©pondre √† la question (domaine‚ÄØ: {domain}).\",\n",
    "                user_question,\n",
    "                extract_context,\n",
    "                \"recherche\"\n",
    "            )\n",
    "            result[\"context\"] = context\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"recherche\",\n",
    "                \"feedback\": verif_search.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_search.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_search\n",
    "            })\n",
    "\n",
    "            # 3. Analyse crois√©e (optionnel mais conseill√©)\n",
    "            # On peut fusionner les contextes (synthese docs + context rag) pour l‚Äôanalyse finale\n",
    "            analyse, verif_analyse, n_attempts_analyse = self.safe_agent_run(\n",
    "                self.agents[\"analyse\"],\n",
    "                {\n",
    "                    \"context\": (base_doc_context or \"\") + \"\\n\\n\" + (context or \"\"),\n",
    "                    \"original_question\": user_question,\n",
    "                    \"reformulated_question\": reformulation\n",
    "                },\n",
    "                \"Synth√©tise les informations cl√©s issues √† la fois des documents import√©s et de la base documentaire interne.\",\n",
    "                user_question,\n",
    "                extract_summary,\n",
    "                \"analyse\"\n",
    "            )\n",
    "            result[\"summary\"] = analyse\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"analyse\",\n",
    "                \"feedback\": verif_analyse.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_analyse.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_analyse\n",
    "            })\n",
    "\n",
    "            # 4. R√©daction finale (r√©ponse claire, enrichie, crois√©e)\n",
    "            answer, verif_redac, n_attempts_redac = self.safe_agent_run(\n",
    "                self.agents[\"redaction\"],\n",
    "                {\n",
    "                    \"original_question\": user_question,\n",
    "                    \"reformulated_question\": reformulation,\n",
    "                    \"summary\": analyse,\n",
    "                    \"context_brut\": (base_doc_context or \"\") + \"\\n\\n\" + (context or \"\")\n",
    "                },\n",
    "                \"R√©dige une r√©ponse synth√©tique et enrichie, croisant l‚Äôinfo des documents import√©s et celle trouv√©e dans la base documentaire interne.\",\n",
    "                user_question,\n",
    "                extract_answer,\n",
    "                \"redaction\"\n",
    "            )\n",
    "            result[\"answer\"] = answer\n",
    "            result[\"verification\"].append({\n",
    "                \"step\": \"redaction\",\n",
    "                \"feedback\": verif_redac.get(\"feedback\", \"\"),\n",
    "                \"valid\": verif_redac.get(\"valid\", False),\n",
    "                \"attempts\": n_attempts_redac\n",
    "            })\n",
    "\n",
    "            result[\"success\"] = True\n",
    "            result[\"attempts\"] = (\n",
    "                (n_attempts_synth if documents else 0)\n",
    "                + n_attempts_search\n",
    "                + n_attempts_analyse\n",
    "                + n_attempts_redac\n",
    "            )\n",
    "            result[\"reason\"] = result.get(\"reason\", \"Pipeline mixte ex√©cut√©e.\")\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a631fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {\n",
    "    \"reception\": agent_reception,\n",
    "    \"analyse\": agent_analyse,\n",
    "    \"redaction\": agent_redaction,\n",
    "    \"conformite\": conformite_agent,  \n",
    "    \"synthese\": synthese_agent,      \n",
    "    \"exigences\": exigences_agent,\n",
    "    \"identification_procedure\": agent_identification_procedure   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98037e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = AgentManager(\n",
    "    agents=agents,\n",
    "    agent_verif=agent_verificateur,\n",
    "    agent_mpc=agent_mpc,\n",
    "    recherche_agents=recherche_agents,  \n",
    "    domains=domains\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14372a8b",
   "metadata": {},
   "source": [
    "#### exemple d'utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = detect_domains(parent_folder)\n",
    "question_utilisateur = \"explique moi ces document j'ai du mal avec ce domaine\"\n",
    "documents = [\n",
    "    {\n",
    "        \"filename\": \"presentation_RAG.pdf\",\n",
    "        \"content\": (\n",
    "            \"Le syst√®me RAG (Retrieval-Augmented Generation) combine les capacit√©s d'un mod√®le g√©n√©ratif avec la recherche documentaire. \"\n",
    "            \"Il permet d'enrichir les r√©ponses d'un assistant IA en allant puiser dans une base de connaissances structur√©e. \"\n",
    "            \"Dans une architecture RAG, l'agent de recherche r√©cup√®re les passages pertinents, l'agent g√©n√©ratif synth√©tise la r√©ponse finale, \"\n",
    "            \"et le processus s'appuie sur des embeddings pour indexer les documents.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"architecture_agents_IA.txt\",\n",
    "        \"content\": (\n",
    "            \"Un agent IA est une entit√© logicielle autonome capable de percevoir son environnement, raisonner, et agir pour atteindre un objectif. \"\n",
    "            \"Dans le contexte du projet, plusieurs agents sp√©cialis√©s (Recherche, Analyse, Conformit√©) coop√®rent pour traiter les requ√™tes complexes. \"\n",
    "            \"Chaque agent utilise des mod√®les d'intelligence artificielle pour comprendre, extraire, et reformuler l'information.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"note_explicative_IA.docx\",\n",
    "        \"content\": (\n",
    "            \"L'intelligence artificielle d√©signe l'ensemble des m√©thodes permettant √† une machine d'apprendre, de raisonner, et d'agir. \"\n",
    "            \"Les assistants bas√©s sur l'IA utilisent le NLP, l'apprentissage automatique, et la recherche de documents (RAG) pour fournir des r√©ponses personnalis√©es. \"\n",
    "            \"L'utilisation d'agents multiples am√©liore la modularit√©, l'explicabilit√©, et la performance du syst√®me.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "result = manager.run_pipeline(\n",
    "    question_utilisateur,\n",
    "    documents=documents,\n",
    ")\n",
    "\n",
    "result[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_multiagent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
